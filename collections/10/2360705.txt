In March 2007, Flickr added new content filtering controls that let members specify by default what types of images they generally upload (photo, art/illustration, or screenshot) and how "safe" (i.e., unlikely to offend others) their images are, as well as specify that information for specific images individually.[62] Individual images are assigned to one of three categories: "safe", "moderate" and "restricted".[63] Users can specify the same criteria when searching for images. There are some restrictions on searches for certain types of users: non-members must always use SafeSearch, which omits images noted as potentially offensive, while members whose Yahoo accounts indicate that they are underage may use SafeSearch or moderate SafeSearch, but cannot turn SafeSearch off completely. The system achieves a fairly good separation of family-friendly photos and adult content; generic image searches normally produce no pornographic results, with the visibility of adult content restricted to users and dedicated Flickr communities who have opted into viewing it.[63]